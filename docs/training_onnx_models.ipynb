{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Fine-Tuning ResNet with BlobDatabase\n",
    "\n",
    "In this tutorial, we will walk through the process of training a Deep Learning model to classify blobs using data stored in a `BlobDatabase`. \n",
    "\n",
    "### What we will cover:\n",
    "1.  **Concepts**: Understanding Transfer Learning and ResNet.\n",
    "2.  **Data Preparation**: Using `BlobDatabase` to create PyTorch Datasets with a proper train/validation split.\n",
    "3.  **Model Setup**: Modifying a pre-trained ResNet50 for our specific classes.\n",
    "4.  **Training**: The training loop with validation.\n",
    "5.  **Export**: Saving the model to ONNX format for deployment.\n",
    "\n",
    "### Prerequisites\n",
    "Ensure you have the following files in your directory:\n",
    "* `example.blobdb` (Your Blob Database)\n",
    "* `BlobDatabase.py` (The class file created in the previous step)\n",
    "\n",
    "And install the required libraries:\n",
    "```bash\n",
    "pip install videometer torch torchvision scikit-learn onnx onnxruntime\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Concepts: Why ResNet and Transfer Learning?\n",
    "\n",
    "**ResNet (Residual Network)** is a powerful convolutional neural network architecture that uses \"skip connections\" to allow gradients to flow easily during training. This enables the training of very deep networks (like the 50-layer version we will use) without the performance degrading.\n",
    "\n",
    "**Fine-Tuning (Transfer Learning)** is the technique of taking a model already trained on a massive dataset (like ImageNet, with 1.2 million images) and adapting it to a new, smaller task. \n",
    "\n",
    "* **Why?** The early layers of the network have already learned to detect edges, textures, and shapes. We only need to \"teach\" the final layers to recognize the specific difference between your classes. This requires far less data and training time than starting from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from videometer.BlobDatabase import BlobDatabase, BlobDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Splitting\n",
    "\n",
    "We need to create two separate datasets: one for **training** (where the model learns) and one for **validation** (where we check its progress).\n",
    "\n",
    "We will use a **robust splitting strategy**:\n",
    "1.  Extract the list of all blob IDs and their labels.\n",
    "2.  Shuffle and split these IDs.\n",
    "3.  Create two separate `BlobDataset` objects.\n",
    "4.  Apply **Data Augmentation** (random resizing, flipping) only to the training set to make the model robust.\n",
    "5.  Apply standard **Normalization** to the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Initialize Database\n",
    "db_path = \"example.blobdb\"\n",
    "db = BlobDatabase(db_path)\n",
    "\n",
    "# 2. Get the raw list of samples (IDs and Labels) without loading images yet\n",
    "# We use a temporary dataset wrapper to fetch the index map efficiently\n",
    "temp_ds = db.get_dataset(target_class_type=\"reference\")\n",
    "all_samples = temp_ds.samples\n",
    "class_map = temp_ds.class_map\n",
    "num_classes = len(class_map)\n",
    "\n",
    "print(f\"Found {len(all_samples)} samples.\")\n",
    "print(f\"Classes: {class_map}\")\n",
    "\n",
    "# 3. Split IDs into Train (80%) and Validation (20%)\n",
    "train_samples, val_samples = train_test_split(all_samples, test_size=0.2, random_state=42, stratify=[s[1] for s in all_samples])\n",
    "\n",
    "print(f\"Training count: {len(train_samples)}\")\n",
    "print(f\"Validation count: {len(val_samples)}\")\n",
    "\n",
    "# 4. Define Transforms\n",
    "# ImageNet stats for normalization\n",
    "norm_mean = [0.485, 0.456, 0.406]\n",
    "norm_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(norm_mean, norm_std)\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(norm_mean, norm_std)\n",
    "])\n",
    "\n",
    "# 5. Create Datasets using the factory constructor logic\n",
    "train_dataset = BlobDataset(db_path, train_samples, class_map, transform=train_transforms)\n",
    "val_dataset = BlobDataset(db_path, val_samples, class_map, transform=val_transforms)\n",
    "\n",
    "# 6. Create DataLoaders\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2),\n",
    "    'val': DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
    "}\n",
    "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Setup\n",
    "\n",
    "We load a pre-trained **ResNet50**. \n",
    "The original model outputs 1000 classes (for ImageNet). We must replace the final fully connected layer (`fc`) to output `num_classes` (the number of classes in your database)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect device (CUDA, MPS for Mac, or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load pre-trained ResNet50\n",
    "model = models.resnet50(weights='IMAGENET1K_V1')\n",
    "\n",
    "# Modify the final layer\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "# Move model to GPU/CPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop\n",
    "\n",
    "We define the logic to train the model. This includes:\n",
    "1.  **Forward Pass**: Compute predictions.\n",
    "2.  **Loss Calculation**: Compare prediction to truth (CrossEntropy).\n",
    "3.  **Backward Pass**: Calculate gradients.\n",
    "4.  **Optimizer Step**: Update weights.\n",
    "\n",
    "We save the best model weights based on validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=5):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                # Track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if phase == 'train' and scheduler:\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Deep copy the model if it's the best one so far\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "# Using SGD with momentum is standard for ResNet fine-tuning\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Run Training\n",
    "trained_model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export to ONNX\n",
    "\n",
    "ONNX (Open Neural Network Exchange) is a standard format for representing machine learning models. Exporting to ONNX allows you to run this model in other languages (C++, C#, etc.) or on edge devices without needing Python or PyTorch installed.\n",
    "\n",
    "We specify `dynamic_axes` to allow the batch size to vary (e.g., process 1 image or 100 images at once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNX_PATH = \"blob_resnet50.onnx\"\n",
    "\n",
    "# 1. Create a dummy input matching the input size (1 batch, 3 channels, 224x224)\n",
    "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "\n",
    "# 2. Export\n",
    "torch.onnx.export(\n",
    "    trained_model,\n",
    "    dummy_input,\n",
    "    ONNX_PATH,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},  # Variable length axes\n",
    "        'output': {0: 'batch_size'}\n",
    "    }\n",
    ")\n",
    "print(f\"Model exported to {ONNX_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Verify ONNX Model\n",
    "\n",
    "It is best practice to verify that the exported model produces the same results as the PyTorch model. We utilize `onnxruntime` for this verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Run inference with PyTorch\n",
    "trained_model.eval()\n",
    "with torch.no_grad():\n",
    "    torch_out = trained_model(dummy_input)\n",
    "\n",
    "# 2. Run inference with ONNX Runtime\n",
    "ort_session = onnxruntime.InferenceSession(ONNX_PATH, providers=['CPUExecutionProvider'])\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(dummy_input)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "# 3. Compare\n",
    "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "print(\"âœ… Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
